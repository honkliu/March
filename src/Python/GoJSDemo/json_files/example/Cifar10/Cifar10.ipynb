{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Input, Conv2D, Dense, MaxPooling2D, Flatten, Dropout\n",
    "from keras.datasets.cifar10 import load_data\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "\n",
    "def get_model_0 (X):\n",
    "    Conv2D_1__ = Conv2D (filters=32, padding=\"same\", activation=\"relu\", kernel_size=(3, 3))\n",
    "    Conv2D_1_out_port_0 = Conv2D_1__ (X)\n",
    "    Conv2D_2__ = Conv2D (filters=32, activation=\"relu\", kernel_size=(3, 3))\n",
    "    Conv2D_2_out_port_0 = Conv2D_2__ (Conv2D_1_out_port_0)\n",
    "    MaxPooling2D_1__ = MaxPooling2D ()\n",
    "    MaxPooling2D_1_out_port_0 = MaxPooling2D_1__ (Conv2D_2_out_port_0)\n",
    "    Dropout_1__ = Dropout (rate=0.25)\n",
    "    Dropout_1_out_port_0 = Dropout_1__ (MaxPooling2D_1_out_port_0)\n",
    "    Conv2D_3__ = Conv2D (filters=64, padding=\"same\", activation=\"relu\", kernel_size=(3, 3))\n",
    "    Conv2D_3_out_port_0 = Conv2D_3__ (Dropout_1_out_port_0)\n",
    "    Conv2D_4__ = Conv2D (filters=64, activation=\"relu\", kernel_size=(3, 3))\n",
    "    Conv2D_4_out_port_0 = Conv2D_4__ (Conv2D_3_out_port_0)\n",
    "    MaxPooling2D_2__ = MaxPooling2D ()\n",
    "    MaxPooling2D_2_out_port_0 = MaxPooling2D_2__ (Conv2D_4_out_port_0)\n",
    "    Dropout_2__ = Dropout (rate=0.25)\n",
    "    Dropout_2_out_port_0 = Dropout_2__ (MaxPooling2D_2_out_port_0)\n",
    "    Flatten_1__ = Flatten ()\n",
    "    Flatten_1_out_port_0 = Flatten_1__ (Dropout_2_out_port_0)\n",
    "    Dense_1__ = Dense (units=512, activation=\"relu\")\n",
    "    Dense_1_out_port_0 = Dense_1__ (Flatten_1_out_port_0)\n",
    "    Dropout_3__ = Dropout (rate=0.5)\n",
    "    Dropout_3_out_port_0 = Dropout_3__ (Dense_1_out_port_0)\n",
    "    Dense_2__ = Dense (units=10, activation=\"softmax\")\n",
    "    Dense_2_out_port_0 = Dense_2__ (Dropout_3_out_port_0)\n",
    "    Y = Dense_2_out_port_0\n",
    "    return Y\n",
    "\n",
    "\n",
    "class SendMetrics (Callback):\n",
    "    #Keras callback to send metrics to NNI framework\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        #Run on end of each epoch\n",
    "        nni.report_intermediate_result(logs[\"val_acc\"])\n",
    "    \n",
    "\n",
    "\n",
    "def generate_default_params ():\n",
    "    return {'epochs': 5, 'optimizer_params': {'momentum': '0.9', 'lr': '0.001', 'decay': '0.'}, 'rho': 0.9, 'lr': 0.001, 'optimizer': 'SGD', 'beta_2': 0.999, 'schedule_decay': 0.004, 'batch_size': 32, 'loss': 'categorical_crossentropy', 'momentum': 0.9, 'beta_1': 0.9, 'decay': 0.0}\n",
    "\n",
    "\n",
    "def get_data ():\n",
    "    # get public data\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "    x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "def get_model ():\n",
    "    X = Input(batch_shape=[None, 32, 32, 3])\n",
    "    Y = get_model_0 (X=X)\n",
    "    return Model([X], [Y])\n",
    "\n",
    "\n",
    "def model_summary (filename):\n",
    "    #generate summary to file\n",
    "    model = get_model()\n",
    "    with open(filename, 'w') as fn:\n",
    "        model.summary(print_fn=lambda x: fn.write(x+\"\\n\"))        \n",
    "    \n",
    "\n",
    "\n",
    "def train ():\n",
    "    model = get_model()\n",
    "    (x_train, y_train), (x_test, y_test) = get_data()\n",
    "    optimizer = None\n",
    "    if params[\"optimizer\"] == 'SGD':\n",
    "        optimizer = SGD(momentum=params[\"momentum\"], lr=params[\"lr\"], decay=params['decay'])\n",
    "    elif params[\"optimizer\"] == 'Adam':\n",
    "        optimizer = Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params[\"beta_2\"],decay=params[\"decay\"])\n",
    "    elif params[\"optimizer\"] == 'RMSprop':\n",
    "        optimizer = RMSprop(lr=params[\"lr\"], rho=params[\"rho\"], decay=params[\"decay\"])\n",
    "    elif params[\"optimizer\"] == 'Adagrad':\n",
    "        optimizer = Adagrad(lr=params[\"lr\"], decay=params[\"decay\"])\n",
    "    elif params[\"optimizer\"] == 'Adadelta':\n",
    "        optimizer = Adadelta(lr=params[\"lr\"], rho=params[\"rho\"], decay=params[\"decay\"])\n",
    "    elif params[\"optimizer\"] == 'Adamax':\n",
    "        optimizer = Adamax(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params[\"beta_2\"],decay=params[\"decay\"])\n",
    "    elif params[\"optimizer\"] == 'Nadam':\n",
    "        optimizer = Nadam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params[\"beta_2\"],schedule_decay=params[\"schedule_decay\"])\n",
    "    model.compile(optimizer=optimizer, loss=params['loss'], metrics=['accuracy'])\n",
    "    hist = model.fit(x_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'], validation_split=0.2,shuffle=True,callbacks=[SendMetrics()])\n",
    "    score = model.evaluate(x_test, y_test, batch_size=params['batch_size'])\n",
    "    model.save('m.h5')\n",
    "    nni.report_final_result(score[1])\n",
    "    return hist.history, score\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "received_params = nni.get_next_parameter()\n",
    "params = generate_default_params()\n",
    "params.update(received_params)\n",
    "hist, score = train()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function of strip_consts\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "# define the function to show the graph\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    K.set_session(sess)\n",
    "    model = get_model()\n",
    "show_graph(tf.get_default_graph().as_graph_def())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "Kernel Spec"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
